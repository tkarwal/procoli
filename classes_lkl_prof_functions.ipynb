{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2673a488-fb5b-458d-98b6-6fc1812876f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdist import mcsamples, plots, chains\n",
    "from getdist.mcsamples import MCSamplesError\n",
    "import numpy as np\n",
    "from subprocess import run\n",
    "import os\n",
    "from yaml import dump\n",
    "from cobaya.yaml import yaml_load_file\n",
    "from copy import deepcopy\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d65beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lkl_prof:\n",
    "    \n",
    "    def __init__(self, chains_dir, chain_file, prof_param, processes=6, R_minus_1_wanted=0.05, \n",
    "                 mcmc_chain_settings={'ignore_rows' : 0.3}, \n",
    "                 minimizer_settings={'minimize': {'method': 'bobyqa','covmat' : 'auto',}}, \n",
    "                 prof_incr=None, prof_min=None, prof_max=None\n",
    "                ):\n",
    "        self.chains_dir = chains_dir\n",
    "        self.chain_file = chain_file\n",
    "        \n",
    "        self.processes = processes\n",
    "        self.R_minus_1_wanted = R_minus_1_wanted\n",
    "        self.mcmc_chain_settings = mcmc_chain_settings\n",
    "        self.minimizer_settings = minimizer_settings\n",
    "        \n",
    "        self.prof_param = prof_param\n",
    "        self.prof_incr = prof_incr\n",
    "        self.prof_min = prof_min\n",
    "        self.prof_max = prof_max\n",
    "        \n",
    "        os.chdir(self.chains_dir)\n",
    "    \n",
    "    def check_mcmc_chains(self):\n",
    "        \"\"\"\n",
    "        Check if mcmc chains chains exist \n",
    "        \n",
    "        :return: True if files found, else False \n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.mcmc_chains = mcsamples.loadMCSamples(self.chains_dir+self.chain_file, settings=self.mcmc_chain_settings)\n",
    "            return True\n",
    "        except OSError:\n",
    "            return False \n",
    "        \n",
    "    def run_mcmc(self, resume=False):\n",
    "        \"\"\"\n",
    "        Run or resume MCMC chains \n",
    "        \n",
    "        :return: True if files found, else False \n",
    "        \"\"\"\n",
    "        self.mcmc_yaml = yaml_load_file(self.chains_dir+self.chain_file+'.yaml')\n",
    "        try:\n",
    "            self.mcmc_yaml['sampler']['mcmc']['Rminus1_stop'] = self.R_minus_1_wanted\n",
    "        except KeyError:\n",
    "            print(\"Error: Input yaml not set up correctly for an mcmc run. Please ensure the sampler 'mcmc' is correctly set. \")\n",
    "            raise KeyError\n",
    "        if self.mcmc_yaml['output'].count('/') > 1:\n",
    "            print(\"Error: For correct functioning of the code, please have the input .yaml file in the same directory as the output chains. Currently, output is: \"+self.mcmc_yaml['output'])\n",
    "            raise OSError\n",
    "        if resume==False:\n",
    "            run(\"mpirun -np \"+str(self.processes)+\" cobaya-run \"+self.chain_file+\".yaml\", shell=True)\n",
    "        else:\n",
    "            run(\"mpirun -np \"+str(self.processes)+\" cobaya-run \"+self.chain_file+\".yaml -r\", shell=True)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def check_mcmc_convergence(self, mcmc_chains=None):\n",
    "        \"\"\"\n",
    "        Check if MCMC converged \n",
    "        \n",
    "        :mcmc_chains: getdist MCSamples instance \n",
    "        \n",
    "        :return: True if MCMC chains have converged to the desired R-1, default is R-1=0.05. Else False \n",
    "        \"\"\"\n",
    "        if mcmc_chains==None:\n",
    "            mcmc_chains=self.mcmc_chains\n",
    "            \n",
    "        current_R_minus_1 = mcmc_chains.getGelmanRubin()\n",
    "        if current_R_minus_1 < self.R_minus_1_wanted:\n",
    "            print(\"Chains converged sufficiently. Current R-1 = {:.3f} satisfies R-1 wanted = {:.3f}. \\nMove on to checking minimum.\".format(current_R_minus_1,self.R_minus_1_wanted))\n",
    "            return True\n",
    "        else: \n",
    "            print(\"Chains not converged. Current R-1 = {:.3f} while R-1 wanted = {:.3f}. \\nResuming MCMC. \".format(current_R_minus_1,self.R_minus_1_wanted))\n",
    "            return False \n",
    "    \n",
    "    def mcmc(self):\n",
    "        \"\"\"\n",
    "        Check MCMC and run if needed \n",
    "        \n",
    "        :return: True once finished \n",
    "        \"\"\"\n",
    "        if not self.check_mcmc_chains():\n",
    "            self.run_mcmc()\n",
    "        elif not self.check_mcmc_convergence():\n",
    "            self.run_mcmc(resume=True)\n",
    "        return True\n",
    "\n",
    "    def check_global_min(self, mcmc_chains=None):\n",
    "        \"\"\"\n",
    "        Check if minimizer was run\n",
    "        \n",
    "        :mcmc_chains: getdist MCSamples instance \n",
    "        \n",
    "        :return: True if global minimum was run and relevant files are accesible. Else False \n",
    "        \"\"\"\n",
    "        if mcmc_chains==None:\n",
    "            mcmc_chains=self.mcmc_chains\n",
    "            \n",
    "        try:\n",
    "            mcmc_chains.getParamBestFitDict()\n",
    "            min_yaml = yaml_load_file(self.chains_dir+self.chain_file+'.minimize.updated.yaml')\n",
    "            print(\"check_global_min: Found previously run MCMC chains and global minimizer. \")\n",
    "            return True\n",
    "        except MCSamplesError:\n",
    "            print(\"check_global_min: Need to first run a minimizer on the full MCMC chains before beginning 1d profile lkl code.\")\n",
    "            return False \n",
    "        except FileNotFoundError:\n",
    "            print(\"check_global_min: Found best-fit but not the file \"+self.chains_dir+self.chain_file+\".minimize.updated.yaml. Something has gone wrong. \")\n",
    "            return FileNotFoundError    \n",
    "        \n",
    "    def global_min(self):\n",
    "        \"\"\"\n",
    "        Check global minizer, run if needed, then write if not already written \n",
    "        \n",
    "        So: \n",
    "        1) load the global minimum file. \n",
    "        2) check if we have a file with prof lkl values. \n",
    "            * If yes, check that it has the same parameters and in the right order. Proceed. \n",
    "            * If no file, start it and write the first line as param names. Proceed. \n",
    "            * If file yes, but parameters don't match, then print an error. Stop. \n",
    "        2) check if global minimum params have already been written (first line of file)\n",
    "            * If parameters are written, check that they match global minimum. Don't write them again\n",
    "            * If parameters are written but don't match, spit out error. \n",
    "            * If no params written, add this current ML values for all parameters in append mode\n",
    "        \n",
    "        :return: global maximum lkl dictionary \n",
    "        \"\"\"\n",
    "        if not self.check_global_min():\n",
    "            self.min_yaml = yaml_load_file(self.chains_dir+self.chain_file+'.input.yaml')\n",
    "            self.min_yaml['sampler'] = self.minimizer_settings\n",
    "\n",
    "            with open(self.chains_dir + self.chain_file + '.minimize.input.yaml', 'w') as yaml_file:\n",
    "                dump(self.min_yaml, yaml_file, default_flow_style=False)\n",
    "\n",
    "            self.run_minimizer(yaml_ext='') # had also passed debug=True here. Can't remember why.  \n",
    "            \n",
    "        param_names, param_ML, MLs = self.read_minimum(extension='')\n",
    "        self.global_ML = deepcopy(MLs)\n",
    "        self.param_order = param_names\n",
    "        \n",
    "        try:\n",
    "            self.match_param_names(self.param_order)\n",
    "        except FileNotFoundError:\n",
    "            extension = '_lkl_profile.txt'\n",
    "            print(\"File not found. Starting a new file now: \" + self.chains_dir + self.chain_file + self.pn_ext(extension) + '\\n')\n",
    "            with open(self.chains_dir + self.chain_file + self.pn_ext(extension), 'w') as lkl_txt:\n",
    "                lkl_txt.write(\"#\")\n",
    "                for param_recorded in self.param_order:\n",
    "                    lkl_txt.write(\"\\t %s\" % param_recorded)\n",
    "                lkl_txt.write(\"\\n\")\n",
    "                \n",
    "        extension = '_lkl_profile.txt'\n",
    "        lkl_prof_table = np.loadtxt(self.chains_dir + self.chain_file + self.pn_ext(extension))\n",
    "\n",
    "        if lkl_prof_table.shape!=(0,):\n",
    "            if not self.match_param_line(self.global_ML, loc=0):\n",
    "                print(\"Something went wrong. The first line of the lkl_profile.txt file which should be global ML does not match the global ML in file \\n\"\n",
    "                     +self.chains_dir + self.chain_file + '.minimum')\n",
    "                raise FileExistsError\n",
    "        else: \n",
    "            self.write_MLs()\n",
    "            \n",
    "        return self.global_ML\n",
    "        \n",
    "        \n",
    "    def pn_ext(self, extension):\n",
    "        \"\"\"\n",
    "        Prefix the file extension string input with the sign of the profile lkl parameter increment to track files correctly. \n",
    "        \n",
    "        :extension: A string of the file name extension without the sign of the prof_parameter \n",
    "        :return: String of extension prefixed with the sign of the increment of profile lkl parameter \n",
    "        \"\"\"\n",
    "        if len(extension)>0:\n",
    "            if self.prof_incr > 0:\n",
    "                extension = '_p'+extension\n",
    "            if self.prof_incr < 0:\n",
    "                extension = '_n'+extension\n",
    "        return extension\n",
    "        \n",
    "    def read_minimum(self, extension='_lkl_prof'):\n",
    "        \"\"\"\n",
    "        Read minimum file and save parameter names list, parameter values list and MLs dictionary \n",
    "        \n",
    "        :extension: The extension of the life type being read in. Leave this as is, the rest of the code assumes the same naming conventions. \n",
    "        \n",
    "        :return: List of parameter names, list of parameter ML values, dictionary of {'param_names': param_ML_value}\n",
    "        \"\"\"\n",
    "        extension=self.pn_ext(extension)\n",
    "        \n",
    "        param_ML, param_names = np.loadtxt(self.chains_dir + self.chain_file + extension + '.minimum', skiprows=3, usecols = (1,2), dtype=str, unpack=True)\n",
    "        param_ML = param_ML.astype(float)\n",
    "        \n",
    "        with open(self.chains_dir + self.chain_file + extension + '.minimum') as min_file:\n",
    "            loglkl_and_chi = [next(min_file) for x in range(2)] # reading in the first two lines separately for -log(lkl) and chi^2\n",
    "        for line in loglkl_and_chi:\n",
    "            param_names = np.append(param_names, line.split(\"=\")[0])\n",
    "            param_ML = np.append(param_ML, float(line.split(\"=\")[1]))\n",
    "        MLs = dict(zip(param_names, param_ML))\n",
    "        \n",
    "        self.param_names = param_names\n",
    "        self.MLs = MLs\n",
    "        \n",
    "        return param_names, param_ML, MLs\n",
    "    \n",
    "    def read_lkl_output(self, extension='_lkl_profile.txt', loc=-1):\n",
    "        \"\"\"\n",
    "        Read (default = last) line of lkl prof output file into list\n",
    "        \n",
    "        :extension: Leave this alone, thank you. \n",
    "        :loc: integer location of line in file to read. Default is last line \n",
    "        \n",
    "        :return: List of parameters\n",
    "        \"\"\"\n",
    "\n",
    "        extension=self.pn_ext(extension)\n",
    "\n",
    "        lkl_prof_table = np.loadtxt(self.chains_dir + self.chain_file + extension)\n",
    "        try:\n",
    "            lkl_prof_table.shape[1] # check that lkl_prof_table has multiple rows\n",
    "            lkl_prof_table = lkl_prof_table[loc, :]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        return lkl_prof_table\n",
    "    \n",
    "    def write_MLs(self, MLs=None, extension='_lkl_profile.txt'):\n",
    "        \"\"\"\n",
    "        Write params from MLs dict into txt file in append mode\n",
    "        Note that to write, we use self.param_order, not self.param_names. \n",
    "        This is because the global param_names list is the one that has the correct order. \n",
    "        \n",
    "        :extension: Leave it alone, thank you.\n",
    "        \n",
    "        :return: new length of the saved lkl profile table\n",
    "        \n",
    "        \"\"\"\n",
    "        if MLs == None:\n",
    "            MLs = self.MLs\n",
    "        extension=self.pn_ext(extension)\n",
    "        \n",
    "        with open(self.chains_dir + self.chain_file + extension, 'a') as lkl_txt:\n",
    "            for param in self.param_order:\n",
    "                lkl_txt.write(\"\\t %s\" % str(MLs[param]))\n",
    "            lkl_txt.write(\"\\n\")\n",
    "        lkl_prof_table = np.loadtxt(self.chains_dir + self.chain_file + extension)\n",
    "        return lkl_prof_table.shape\n",
    "    \n",
    "    \n",
    "    def match_param_names(self, param_names, extension='_lkl_profile.txt'):\n",
    "        \"\"\"\n",
    "        Check that param names match in target file and MLs dictionary\n",
    "        \n",
    "        :param_names: List of param_names to check against the file \n",
    "        :extension: Leave it alone, thank you. \n",
    "        \n",
    "        :return: True if param_names match, else False\n",
    "        \"\"\"\n",
    "        \n",
    "        extension=self.pn_ext(extension)\n",
    "        \n",
    "        with open(self.chains_dir + self.chain_file + extension, 'r') as lkl_txt:\n",
    "            params_recorded = lkl_txt.readline()\n",
    "        # define the expected first row of this file\n",
    "        expected_string = '#'\n",
    "        for param in param_names:\n",
    "            expected_string += \"\\t %s\" % param\n",
    "        expected_string += \"\\n\"\n",
    "        if expected_string == params_recorded:\n",
    "            print(\"match_param_names: Found existing file with correct name and parameters / parameter sequence. Will append to it. \\n\" \n",
    "                     + self.chains_dir + self.chain_file + extension)\n",
    "            return True\n",
    "        else:\n",
    "            print(\"match_param_names: Error: existing file found at \" + self.chains_dir + self.chain_file + extension \n",
    "                 + \"\\n but parameters / parameter sequence does not match expected.\")\n",
    "            print(\"--> parameters found: \\n\" + params_recorded)\n",
    "            print(\"--> parameters expected: \\n\" + expected_string)\n",
    "            raise FileExistsError\n",
    "            return False\n",
    "    \n",
    "    def match_param_line(self, MLs, param_names=None, extension='_lkl_profile.txt', loc=-1):\n",
    "        \"\"\"\n",
    "        Check if specified (default: last) location in lkl_prof output file matches current MLs\n",
    "        \n",
    "        :param_names: list of parameter names in the same order as that printed in the file. \n",
    "                        This is usually the global param_order list. \n",
    "        :MLs: dictionary of {'param_name': ML_value }\n",
    "        :extension: Leave it alone, thank you. \n",
    "        :loc: integer location of row in file to check, default is the last line\n",
    "        \n",
    "        :return: True if match, else False \n",
    "        \"\"\"\n",
    "        \n",
    "        extension=self.pn_ext(extension)\n",
    "        \n",
    "        if param_names==None:\n",
    "            param_names=self.param_order\n",
    "\n",
    "        lkl_prof_table = np.loadtxt(self.chains_dir + self.chain_file + extension)\n",
    "        if lkl_prof_table.size==0:\n",
    "            print(\"match_param_line: File empty \")\n",
    "            return False\n",
    "        else: \n",
    "            try:\n",
    "                lkl_prof_table.shape[1] # check that lkl_prof_table has multiple rows\n",
    "                if False in [lkl_prof_table[loc, np.where(param_names == param)] == MLs[param] for param in param_names]:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True \n",
    "            except IndexError:\n",
    "                print(\"match_param_line: Only one entry in file, checking that entry \")\n",
    "                if False in [lkl_prof_table[np.where(param_names == param)] == MLs[param] for param in param_names]:\n",
    "                    return False \n",
    "                else:\n",
    "                    return True               \n",
    "\n",
    "\n",
    "    def increment_update_yaml(self, MLs, lkl_pro_yaml, yaml_ext = '_lkl_prof'):\n",
    "        \"\"\"\n",
    "        Update yaml info to next increment \n",
    "        \n",
    "        \n",
    "        :MLs: dictionary of {'param_name': ML_value }\n",
    "        :lkl_pro_yaml: dictionary of yaml info for running lkl profile incremental minimizer \n",
    "        :yaml_ext: Leave it alone. \n",
    "        \n",
    "        :return: dictionary for yaml info of profile lkl parameter, including incremented value and latex info\n",
    "        \"\"\"\n",
    "        yaml_ext=self.pn_ext(yaml_ext)\n",
    "        \n",
    "        # update profile lkl param \n",
    "        latex_info = lkl_pro_yaml['params'][self.prof_param]['latex']\n",
    "        lkl_pro_yaml['params'][self.prof_param] = {'value': MLs[self.prof_param]+self.prof_incr, 'latex': latex_info}\n",
    "        lkl_pro_yaml['output'] = self.chain_file + yaml_ext\n",
    "        # update all other independent parameters \n",
    "        for param in lkl_pro_yaml['params']:\n",
    "            if 'prior' in lkl_pro_yaml['params'][param]:\n",
    "                lkl_pro_yaml['params'][param]['ref'] = MLs[param]\n",
    "        # dump yaml to file for running \n",
    "        with open(self.chains_dir+self.chain_file+yaml_ext+'.minimize.input.yaml', 'w') as yaml_file:\n",
    "            dump(lkl_pro_yaml, yaml_file, default_flow_style=False)    \n",
    "        return lkl_pro_yaml['params'][self.prof_param]\n",
    "    \n",
    "    def run_minimizer(self, yaml_ext='_lkl_prof', debug=False):\n",
    "        \"\"\"\n",
    "        Run minimizer \n",
    "        For the parameter we want to vary, remove all but latex and value. \n",
    "        The latex is as before from the MCMC yaml file. \n",
    "        The value is ML $\\pm$ increment. \n",
    "        \n",
    "        :yaml_ext: Leave it alone. \n",
    "        :debug: Do you want Cobaya debug output (it's a LOT)\n",
    "        \n",
    "        :return: True\n",
    "        \"\"\"\n",
    "        yaml_ext=self.pn_ext(yaml_ext)\n",
    "\n",
    "        if debug==True:\n",
    "            run(\"mpirun -np \"+str(self.processes)+\" cobaya-run \"+self.chain_file+yaml_ext+\".minimize.input.yaml -f -d\", shell=True)\n",
    "        else:\n",
    "            run(\"mpirun -np \"+str(self.processes)+\" cobaya-run \"+self.chain_file+yaml_ext+\".minimize.input.yaml -f\", shell=True)   \n",
    "        return True\n",
    "    \n",
    "    def init_lkl_prof(self):\n",
    "        \"\"\"\n",
    "        Initialise profile lkl yaml:\n",
    "        1) copy the global minimiser yaml into a profile lkl yaml if not already done, \n",
    "        and set the sampler to minimiser settings specified in the class call, \n",
    "        and the covamt to the global mcmc covmat. \n",
    "        2) read the last line of the lkl output file and set that as the current MLs dictionary, as self.MLs. \n",
    "        this updates the location in prof_param that we're at for running prof lkls \n",
    "        3) set self.lkl_pro_yaml as a dictionary of this modified global minimiser yaml \n",
    "        \n",
    "        :return: the lkl profile yaml dictionary \n",
    "        \"\"\"\n",
    "        extension = '_lkl_prof'\n",
    "        try:\n",
    "            lkl_pro_yaml = yaml_load_file(self.chains_dir+self.chain_file+self.pn_ext(extension)+'.minimize.input.yaml')\n",
    "        except FileNotFoundError:\n",
    "            run(\"cp \"+self.chains_dir+self.chain_file+'.minimize.updated.yaml'+\" \"\n",
    "                    +self.chains_dir+self.chain_file+self.pn_ext(extension)+'.minimize.input.yaml', shell=True)\n",
    "            lkl_pro_yaml = yaml_load_file(self.chains_dir+self.chain_file+self.pn_ext(extension)+'.minimize.input.yaml')\n",
    "        lkl_pro_yaml['sampler'] = self.minimizer_settings\n",
    "        lkl_pro_yaml['sampler']['minimize']['covmat'] = self.chains_dir+self.chain_file+'.covmat'\n",
    "\n",
    "        param_ML = self.read_lkl_output()\n",
    "        self.MLs = dict(zip(self.param_names, param_ML))\n",
    "        \n",
    "        self.lkl_pro_yaml = deepcopy(lkl_pro_yaml)\n",
    "        \n",
    "        return self.lkl_pro_yaml\n",
    "        \n",
    "    def run_lkl_prof(self, time_mins=False):\n",
    "        \"\"\"\n",
    "        Run the likelihood profile loop. \n",
    "        Initialise time-keeping file if wanted. \n",
    "        \n",
    "        While we are within the bounds of the profile param we want to explore: \n",
    "        1) check if the point we are currently at i.e. param_ML and MLs, matches the last entry in the lkl_prof table.\n",
    "            - if it does, the last minimum was run and saved successfully.\n",
    "            - if not, check if a minimum file exists. \n",
    "                - if it does, read it in and save it in the lkl prof txt. minimum run successfully. \n",
    "                - if not, this happens when we have updated the yaml but the minimizer didn't finish. \n",
    "                  Run the yaml again without updating. \n",
    "        2) check if minimum was run and saved. \n",
    "            - if yes, update the yaml and increment the prof lkl param, \n",
    "              update all other params to new values from current ML. \n",
    "              Assign the MLs values for the independent params in the yaml as new reference starting points. \n",
    "        3) run the minimizer \n",
    "        4) save minimizer output \n",
    "\n",
    "        :time_mins: boolean for whether you want to time each minimiser increment or not \n",
    "        \n",
    "        :return: the value of the profile lkl parameter at the end of this loop \n",
    "        \"\"\"\n",
    "        if time_mins == True:\n",
    "            time_extension = '_time_stamps.txt'\n",
    "            time_extension = self.pn_ext(time_extension)\n",
    "            with open(self.chains_dir + self.chain_file + time_extension, 'w') as lkl_txt:\n",
    "                lkl_txt.write(\"#\")\n",
    "                lkl_txt.write(\" %s \\t step_size \\t minimizer_time \" % self.prof_param)\n",
    "                lkl_txt.write(\"\\n\")\n",
    "\n",
    "        extension = '_lkl_prof'\n",
    "        extension = self.pn_ext(extension)\n",
    "\n",
    "        MLs = deepcopy(self.MLs)\n",
    "        lkl_pro_yaml = deepcopy(self.lkl_pro_yaml)\n",
    "\n",
    "        while ((MLs[self.prof_param] < self.prof_max) and (MLs[self.prof_param] > self.prof_min)):\n",
    "            last_entry_matches_current_params = self.match_param_line(MLs)\n",
    "            if last_entry_matches_current_params:\n",
    "                run('rm '+self.chains_dir + self.chain_file + extension + '.minimum*', shell=True)\n",
    "                minimum_successfully_run_and_saved = True\n",
    "            else:\n",
    "                try:\n",
    "                    param_names, param_ML, MLs = self.read_minimum()\n",
    "                    self.write_MLs(MLs)\n",
    "                    run('rm '+self.chains_dir + self.chain_file + extension + '.minimum*', shell=True)\n",
    "                    minimum_successfully_run_and_saved = True \n",
    "                    print(\"-----> Minimizer run successfully for \"+self.prof_param+\" = \"+str(MLs[self.prof_param]))\n",
    "                except OSError:\n",
    "                    minimum_successfully_run_and_saved = False\n",
    "                    print(\"-----> Minimizer not run for \"+self.prof_param+\" = \"+str(MLs[self.prof_param]))\n",
    "                    print(\"       Rerunning this point\")\n",
    "\n",
    "            if minimum_successfully_run_and_saved:\n",
    "                self.increment_update_yaml(MLs, lkl_pro_yaml)\n",
    "                run('rm '+self.chains_dir + self.chain_file + extension + '.minimize.updated.yaml', shell=True)\n",
    "\n",
    "            time_start = time()\n",
    "\n",
    "            self.run_minimizer()\n",
    "\n",
    "            time_end = time()\n",
    "            time_taken = time_end - time_start\n",
    "\n",
    "            if time_mins == True:\n",
    "                with open(self.chains_dir + self.chain_file + time_extension, 'a') as lkl_txt:\n",
    "                    lkl_txt.write(\"{:.4g} \\t {:.2g} \\t {:.2f} \\n\".format(lkl_pro_yaml['params'][self.prof_param]['value'], \n",
    "                                                                         self.prof_incr, time_taken))\n",
    "                print(\"       Time taken for minimizer = {:.2f}\".format(time_taken))\n",
    "\n",
    "            param_names, param_ML, MLs = self.read_minimum()\n",
    "\n",
    "    #         prof_incr *= 2. # Readjust prof lkl increment if wanted by copying this function and adding such a line \n",
    "\n",
    "        # outside loop now \n",
    "        last_entry_matches_current_params = self.match_param_line(MLs)\n",
    "        if not last_entry_matches_current_params:\n",
    "            param_names, param_ML, MLs = self.read_minimum()\n",
    "            self.write_MLs(MLs)\n",
    "            print(\"-----> Minimizer run successfully for \"+self.prof_param+\" = \"+str(MLs[self.prof_param]))\n",
    "        \n",
    "        return MLs[self.prof_param]\n",
    "    \n",
    "    \n",
    "    def full_lkl_prof_array(self):\n",
    "        \"\"\"\n",
    "        Combine positive and negative increment files into one array \n",
    "        \n",
    "        :return: full likelihood profile array \n",
    "        \"\"\"\n",
    "        try:\n",
    "            all_MLs_p = np.loadtxt(self.chains_dir+self.chain_file+'_p_lkl_profile.txt')\n",
    "            pos_file = True\n",
    "        except OSError:\n",
    "            pos_file = False\n",
    "        try:\n",
    "            all_MLs_n = np.loadtxt(self.chains_dir+self.chain_file+'_n_lkl_profile.txt')\n",
    "            if pos_file==True:\n",
    "                all_MLs = np.concatenate( (np.flip(all_MLs_n, 0),all_MLs_p) )\n",
    "            else:\n",
    "                all_MLs = np.flip(all_MLs_n, 0)\n",
    "        except OSError:\n",
    "            all_MLs = all_MLs_p\n",
    "\n",
    "        return all_MLs\n",
    "\n",
    "    def full_lkl_prof_dict(self):\n",
    "        \"\"\"\n",
    "        Combine positive and negative increment files into one dictionary with \n",
    "        keys = param names \n",
    "        values = 1D array of profile likelihood values \n",
    "        \n",
    "        :return: full likelihood profile dictionary \n",
    "        \"\"\"\n",
    "        full_prof_dict = {}\n",
    "        full_lkl_prof_array = self.full_lkl_prof_array()\n",
    "\n",
    "        for param_num in range(len(self.param_order)):\n",
    "            full_prof_dict[self.param_order[param_num]] = full_lkl_prof_array[:,param_num]\n",
    "\n",
    "        return full_prof_dict\n",
    "\n",
    "    def sum_params(self, params_to_sum):\n",
    "        \"\"\"\n",
    "        Sum list of params and return array of summed params.\n",
    "        Useful for adding up chi^2's post profile lkl run \n",
    "        \n",
    "        :params_to_sum: list of parameter names that you want to sum. \n",
    "        \n",
    "        :return: array of summed parameters \n",
    "        \"\"\"\n",
    "        prof_lkl = self.full_lkl_prof_dict()\n",
    "\n",
    "        param_vectors = [prof_lkl[param] for param in params_to_sum]\n",
    "        param_stack = np.stack(param_vectors, axis=0)\n",
    "        summed_params = param_stack.sum(axis=0)\n",
    "\n",
    "        return summed_params\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bea6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e3df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86008b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
