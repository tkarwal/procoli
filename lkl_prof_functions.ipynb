{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2673a488-fb5b-458d-98b6-6fc1812876f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdist import mcsamples, plots, chains\n",
    "from getdist.mcsamples import MCSamplesError\n",
    "import numpy as np\n",
    "from subprocess import run\n",
    "import os\n",
    "from yaml import dump\n",
    "from cobaya.yaml import yaml_load_file\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f1156-2ff3-41eb-bb9e-9531a94f9448",
   "metadata": {},
   "source": [
    "### Variables used for functions and testing them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6b2c47-7892-4541-8b84-e15b7ba4e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chains_dir = \"/Users/tanvikarwal/Desktop/Early_dark_energy/likelihood_profile/chains/lcdm_base/\"\n",
    "# chain_file = 'lcdm_cmb_bao_sne_'\n",
    "# chains_dir = '/home2/karwal/mcmc_chains/ede_lkl_profile/lcdm_base/'\n",
    "# chain_file = 'lcdm_cmb_bao_sne_'\n",
    "# os.chdir(chains_dir)\n",
    "\n",
    "# settings = {'ignore_rows' : 0.2}\n",
    "# mcmc_chains = mcsamples.loadMCSamples(chains_dir+chain_file, settings=settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c20199-5b16-438e-910d-ff66815b4860",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read minimum file and save parameter names and values lists and MLs dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ca0980-e4c4-4fa4-a605-8118e8938185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_minimum(chains_dir, chain_file, extension='_lkl_prof'):\n",
    "    param_ML, param_names = np.loadtxt(chains_dir + chain_file + extension + '.minimum', skiprows=3, usecols = (1,2), dtype=str, unpack=True)\n",
    "    param_ML = param_ML.astype(float)\n",
    "\n",
    "    with open(chains_dir + chain_file + extension + '.minimum') as min_file:\n",
    "        loglkl_and_chi = [next(min_file) for x in range(2)] # reading in the first two lines separately for -log(lkl) and chi^2\n",
    "    for line in loglkl_and_chi:\n",
    "        param_names = np.append(param_names, line.split(\"=\")[0])\n",
    "        param_ML = np.append(param_ML, float(line.split(\"=\")[1]))\n",
    "    MLs = dict(zip(param_names, param_ML))\n",
    "    return param_names, param_ML, MLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4a97e67-e738-4b4e-838b-8c7bac6a3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_names, param_values, MLs = read_minimum(chains_dir=chains_dir, chain_file=chain_file)\n",
    "# MLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e77456-86fc-41c3-8557-b3ea929685b6",
   "metadata": {},
   "source": [
    "### Read last line of lkl prof output file into list and update MLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e429a82-9041-4a77-bf44-d76c8325c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lkl_output(chains_dir, chain_file, extension='_lkl_profile.txt', loc=-1):\n",
    "    lkl_prof_table = np.loadtxt(chains_dir + chain_file + '_lkl_profile.txt')\n",
    "    try:\n",
    "        lkl_prof_table.shape[1] # check that lkl_prof_table has multiple rows\n",
    "        lkl_prof_table = lkl_prof_table[-1, :]\n",
    "    except IndexError:\n",
    "        pass\n",
    "    return lkl_prof_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59689ce8-253e-4a37-a3bb-5080fd4f1818",
   "metadata": {},
   "source": [
    "### Write params from MLs dict into txt file in append mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03efca98-9231-40a6-892e-cc76f7b06a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_MLs(param_names, MLs, chains_dir, chain_file, extension='_lkl_profile.txt'):\n",
    "    with open(chains_dir + chain_file + extension, 'a') as lkl_txt:\n",
    "        for param in param_names:\n",
    "            lkl_txt.write(\"\\t %s\" % str(MLs[param]))\n",
    "        lkl_txt.write(\"\\n\")\n",
    "    lkl_prof_table = np.loadtxt(chains_dir + chain_file + extension)\n",
    "    return lkl_prof_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c67fdb4-713c-443f-88e2-8a61e32ecc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_MLs(chains_dir=chains_dir, chain_file=chain_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35d5aa-9008-428d-af02-6e0405c9e552",
   "metadata": {},
   "source": [
    "### Check that param names match in target file and MLs dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b9c2b0a-0af0-48dc-9b04-2e2494caca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_param_names(param_names, chains_dir, chain_file, extension='_lkl_profile.txt'):\n",
    "    with open(chains_dir + chain_file + extension, 'r') as lkl_txt:\n",
    "        params_recorded = lkl_txt.readline()\n",
    "    # params_recorded = params_recorded\n",
    "    # define the expected first row of this file\n",
    "    expected_string = '#'\n",
    "    for param in param_names:\n",
    "        expected_string += \"\\t %s\" % param\n",
    "    expected_string += \"\\n\"\n",
    "    if expected_string == params_recorded:\n",
    "        print(\"match_param_names: Found existing file with correct name and parameters / parameter sequence. Will append to it. \\n\" \n",
    "                 + chains_dir + chain_file + extension)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"match_param_names: Error: existing file found at \" + chains_dir + chain_file + extension \n",
    "             + \"\\n but parameters / parameter sequence does not match expected.\")\n",
    "        print(\"--> parameters found: \\n\" + params_recorded)\n",
    "        print(\"--> parameters expected: \\n\" + expected_string)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aea35f4a-05da-47e7-92e8-c54e1f50bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing file with correct name and parameters / parameter sequence. Will append to it. \n",
      "/Users/tanvikarwal/Desktop/Early_dark_energy/likelihood_profile/chains/lcdm_base/lcdm_cmb_bao_sne__lkl_profile.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match_param_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96150242-2810-49ca-95ef-8ce3096f8d52",
   "metadata": {},
   "source": [
    "### Check if some location in lkl_prof output file matches current MLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd54d4ac-83dd-4a3d-8217-d53c2b733e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_param_line(param_names, MLs, chains_dir, chain_file, extension='_lkl_profile.txt', loc=-1):\n",
    "    lkl_prof_table = np.loadtxt(chains_dir + chain_file + '_lkl_profile.txt')\n",
    "    if lkl_prof_table.size==0:\n",
    "        print(\"match_param_line: File empty \")\n",
    "        return False\n",
    "    else: \n",
    "        try:\n",
    "            lkl_prof_table.shape[1] # check that lkl_prof_table has multiple rows\n",
    "            if False in [lkl_prof_table[loc, np.where(param_names == param)] == MLs[param] for param in param_names]:\n",
    "                return False\n",
    "            else:\n",
    "                return True \n",
    "        except IndexError:\n",
    "            print(\"match_param_line: Only one entry in file, checking that entry \")\n",
    "            if False in [lkl_prof_table[np.where(param_names == param)] == MLs[param] for param in param_names]:\n",
    "                return False \n",
    "            else:\n",
    "                return True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cb9cf44-a0b9-4586-9873-07f7b11829f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match_param_line(param_names, MLs, loc=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410ca4a-f744-4ea0-aeb3-13e0c8316dd3",
   "metadata": {},
   "source": [
    "### Updated yaml info to next increment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80b34d0b-476c-495d-8b03-c6f0479eb138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_update_yaml(MLs, lkl_pro_yaml, prof_param, prof_incr, yaml_ext = '_lkl_prof'):\n",
    "    # update profile lkl param \n",
    "    latex_info = lkl_pro_yaml['params'][prof_param]['latex']\n",
    "    lkl_pro_yaml['params'][prof_param] = {'value': MLs[prof_param]+prof_incr, 'latex': latex_info}\n",
    "    lkl_pro_yaml['output'] = chain_file + yaml_ext\n",
    "    # update all other independent parameters \n",
    "    for param in lkl_pro_yaml['params']:\n",
    "        if 'prior' in lkl_pro_yaml['params'][param]:\n",
    "            lkl_pro_yaml['params'][param]['ref'] = MLs[param]\n",
    "    # dump yaml to file for running \n",
    "    with open(chains_dir+chain_file+yaml_ext+'.minimize.input.yaml', 'w') as yaml_file:\n",
    "        dump(lkl_pro_yaml, yaml_file, default_flow_style=False)    \n",
    "    return lkl_pro_yaml['params'][prof_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a0468-cd92-4cf1-a10e-48cd577f4ee5",
   "metadata": {},
   "source": [
    "### Run minimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6287ea52-f1c2-4ead-af67-97f9cdb5d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_minimizer(chain_file, yaml_ext='_lkl_prof', debug=False, processes=4):\n",
    "    \"\"\"\n",
    "    For the parameter we want to vary, remove all but latex and value. \n",
    "    The latex is as before from the MCMC yaml file. \n",
    "    The value is ML $\\pm$ increment. \n",
    "    \"\"\"\n",
    "    if debug==True:\n",
    "        run(\"mpirun -np \"+str(processes)+\" cobaya-run \"+chain_file+yaml_ext+\".minimize.input.yaml -f -d\", shell=True)\n",
    "    else:\n",
    "        run(\"mpirun -np \"+str(processes)+\" cobaya-run \"+chain_file+yaml_ext+\".minimize.input.yaml -f\", shell=True)   \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d52d1-4052-413b-aaad-a3316324b691",
   "metadata": {},
   "source": [
    "### Check if minimizer was run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bd5f4e6-8d59-4d55-a3e2-5e0497716047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_global_min(mcmc_chains, chains_dir, chain_file):\n",
    "    try:\n",
    "        mcmc_chains.getParamBestFitDict()\n",
    "        min_yaml = yaml_load_file(chains_dir+chain_file+'.minimize.updated.yaml')\n",
    "        print(\"check_global_min: Found previously run MCMC chains and global minimizer. \")\n",
    "        return True\n",
    "    except MCSamplesError:\n",
    "        print(\"check_global_min: Need to first run a minimizer on the full MCMC chains before beginning 1d profile lkl code.\")\n",
    "        return False \n",
    "    except FileNotFoundError:\n",
    "        print(\"check_global_min: Found best-fit but not the file \"+chains_dir+chain_file+\".minimize.updated.yaml. Something has gone wrong. \")\n",
    "        return FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d0e90-f70c-4df0-bd17-9ed486d2a56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
